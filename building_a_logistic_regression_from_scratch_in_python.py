# -*- coding: utf-8 -*-
"""Building a logistic Regression from scratch in python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tt2y_73Rtr0Ccj4IZoQB1FchVZp-YNBG
"""



"""Import the dependancies"""

#import the numpy library
import numpy as np



"""Logistic regression"""

class Logistic_Regression():
  #initiate the learning rate and no of iterations-hyperparameters
  def __init__(self, learning_rate, no_of_iterations):

    self.learning_rate=learning_rate
    self.no_of_iterations=no_of_iterations

  def fit(self,X,Y):
    #fit he function to train the model with dataset
    self.m,self.n=X.shape

    self.w=np.zeros(self.n)

    self.b=0

    self.X=X

    self.Y=Y

    #implementing gradient descent for optimization
    for i in range (self.no_of_iterations):
      self.update_weights()

  def update_weights(self):
    #Y_hat formula (sigmoid function)
    Y_hat=1/(1+np.exp(-(self.X.dot(self.w)+self.b)))

    #derivatives

    dw=(1/self.m)*np.dot(self.X.T, (Y_hat-self.Y))

    db=(1/self.m)*np.sum(Y_hat-self.Y)

    #sigmoid equation and decision boundery
    self.w = self.w - self.learning_rate * dw
    self.b = self.b - self.learning_rate * db


  def predict(self, X):
    Y_pred = 1/(1 + np.exp(-(X.dot(self.w) + self.b )))
    Y_pred=np.where(Y_pred>0.5,1,0)
    return Y_pred

model=Logistic_Regression(learning_rate=0.01,no_of_iterations=1000)

print(np.exp(1))

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score



"""Data collection and analysis"""

#loading the diabetes dataset to a panddas dataframe
diabetes_dataset=pd.read_csv('/content/diabetes.csv')

diabetes_dataset.head()

diabetes_dataset.shape

diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

diabetes_dataset.groupby('Outcome').mean()

#separating the data and labels
features=diabetes_dataset.drop(columns='Outcome',axis=1)
target=diabetes_dataset['Outcome']

print(features)

print(target)

scaler=StandardScaler()
scaler.fit(features)
StandardScaler(copy=True,with_mean=True,with_std=True)
standardized_data=scaler.transform(features)
print(standardized_data)



"""Data standardization

split the trining data and testing data
"""

X_train,X_test,Y_train,Y_test=train_test_split(features,target,test_size=0.2,random_state=2)

print(X_train.shape,X_test.shape,features.shape)



"""Training the model"""

classifier=Logistic_Regression(learning_rate=0.01,no_of_iterations=1000)

classifier.fit(X_train,Y_train)



"""Accuracy score"""

#accuracy score of the training data
X_train_prediction=classifier.predict(X_train)
training_data_accuracy=accuracy_score(Y_train,X_train_prediction)

print('Accuracy score of the training data:',training_data_accuracy)

#accuracy score of the test data
X_test_prediction=classifier.predict(X_test)
test_data_accuracy=accuracy_score(Y_test,X_test_prediction)

print('Accuracy score of the testing data:',test_data_accuracy)



"""Make a predictive system"""

input_data=( 1,189,60,23,846,30.1,0.398,59)

input_as_numpy_array=np.asarray(input_data)

input_data_reshaped=input_as_numpy_array.reshape(1,-1)

std_data=scaler.transform(input_data_reshaped)

prediction=classifier.predict(std_data)

if (prediction[0]==0):
  print('the person is not diaabetic')
else:
  print('the person is diabetic')

