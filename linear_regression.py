# -*- coding: utf-8 -*-
"""Linear regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TgU3RB8PiiCUH7bduO17bbvvKnLg9tp_
"""

import numpy as np

class linear_regression:
#initiating the parameters(learning rate and no of iterations)
  def __init__(self,learning_rate,no_of_iterations ):
    self.learning_rate=learning_rate
    self.no_of_iterations=no_of_iterations

  def fit(self,x,y ):
#number of training examples and number of features
    self.m,self.n=x.shape  #numbers of rows and columns

    #initiate the wieghts and bais

    self.w=np.zeros(self.n)
    self.b=0
    self.x=x
    self.y=y

    #implementing gradient descent

    for i in range(self.no_of_iterations):
      self.update_weights()


  def update_weights(self, ):
    y_prediction=self.predict(self.x)

    #calculate gradients
    dw= - (2*(self.x.T).dot(self.y-y_prediction))/self.m

    db= -2*np.sum(self.y-y_prediction)/self.m

    #updating the weights
    self.w=self.w-self.learning_rate*self.dw

    self.b=self.b-self.learning_rate*self.db

  def predict(self, ):
    return x.dot(self.w) + self.b

#using linear regression model for prediction
#steps :
#1.setting the learning rate and no of  no_of_iterations ,initiating the weights and bias
#2.Build the Linear regression equation
#3.find the "y pred" value for given x value for the corresponding weight and bias
#4.Check the loss function for the parameter values(difference between y pred and true y)
#5.Update the parameter values using Gradient descent(new weight and bias values)
#6.Step 3,4,5 are repeated till we get the minimumloss function

#import libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#loading the data from csv file to a pandas dataframe
salary_data=pd.read_csv('/content/salary_data.csv')



"""Daata pre-processing"""

#printing the first five columns of our DataFrame
salary_data.head()

salary_data.tail()

salary_data.shape

#checking for missing values

salary_data.isnull().sum()



"""Splitting the target and feature"""

x=salary_data.iloc[:,:-1].values
y=salary_data.iloc[:,1].values

print(x)

print(y)



"""splitting the data into train and test data"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=2)

import numpy as np

class linear_regression:
  def __init__(self,learning_rate,no_of_iterations):
    self.learning_rate=learning_rate
    self.no_of_iterations=no_of_iterations

  def fit(self,x,y):
    self.m,self.n=x.shape

    self.w=np.zeros(self.n)
    self.b=0
    self.x=x
    self.y=y

    for i in range(self.no_of_iterations):
      self.update_weights()

  def update_weights(self, ):
    y_prediction=self.predict()

    #calculate gradients
    dw=-(2*(self.x.T).dot(self.y-y_prediction))/self.m
    db=-2*np.sum(self.y-y_prediction)/self.m

    #update weights
    self.w=self.w-self.learning_rate*dw
    self.b=self.b-self.learning_rate*db

  def predict(self,):
    return self.x.dot(self.w)+self.b

"""Training the linear regression model"""

model=linear_regression(learning_rate=0.02,no_of_iterations=1000)

model.fit(x_train,y_train)

#printing the parameter values
print('weight = ', model.w[0])
print('bias = ', model.b)



"""y=9414(x) + 23697



salary = 9414(experience) + 23697
"""



"""predict the salary value for test data"""

test_data_prediction=model.predict(x_test)

print(test_data_prediction)



"""Vusualizing the predicted values and actual values"""

plt.scatter(x_test,y_test,colour= 'red')
plt.plot(x_test,test_data_prediction,color='blue')

